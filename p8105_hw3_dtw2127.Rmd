---
title: "p8105_hw3_dtw2127"
author: "Dee Wang"
date: "18/10/2021"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE) #do i still need this?
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```

First we'll load in the instacart data and do an exploration of the dataset.

```{r}
data("instacart")

str(instacart)
```

The instacart dataset contains `r nrow(instacart)` rows of data for `r ncol(instacart)` variables. Key variables include order ID, product ID, add to cart order, user ID, order hour of day, days since prior order, and department. 

There are `r pull(instacart, aisle) %>% unique() %>% length()` aisles. Let's determine which aisle the most items are ordered from. 

```{r}
instacart %>% group_by(aisle) %>% summarize(n_obs = n()) %>% slice_max(n_obs, n=3)
```
The most items are ordered from the fresh vegetables, fresh fruits, and packaged vegetables and fruits aisle.  

We'll make a plot that shows the number of items ordered from each aisle. 

```{r}

instacart %>% group_by(aisle, department) %>% summarize(n_obs = n()) %>% filter(n_obs > 10000) %>% 
  ggplot(aes(x = aisle, y = n_obs)) + 
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90))

#arrange bars in ascending order
```

Next we'll create a table showing the three most popular items in each of the aisles "baking ingredients", "dog food care", and "packaged vegetables fruits".

```{r}
instacart %>% filter(aisle %in% c("baking ingredients", "packaged vegetables fruits", "dog food care")) %>% group_by(aisle, product_name) %>% summarize(n_obs = n()) %>% slice_max(order_by = n_obs, n = 3) %>% knitr::kable()

#instacart %>% filter(aisle == c("baking ingredients")) %>% group_by(product_name) %>% summarize(n_obs = n()) %>% slice_max(order_by = n_obs, n = 3) %>% knitr::kable()
#instacart %>% filter(aisle == c("packaged vegetables fruits")) %>% group_by(product_name) %>% summarize(n_obs = n()) %>% slice_max(order_by = n_obs, n = 3) %>% knitr::kable()
#instacart %>% filter(aisle == c("dog food care")) %>% group_by(product_name) %>% summarize(n_obs = n()) %>% slice_max(order_by = n_obs, n = 3) %>% knitr::kable()

```

Next we'll make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week and will format the table for human readers. 


```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(order_dow, product_name) %>% 
  summarize(mean_hour_of_day = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = product_name, 
    values_from = mean_hour_of_day) %>% 
  knitr::kable(digits = 1)
```

## Problem 2

First, let's load in the BRFSS data and then do some data cleaning. 

```{r}
data("brfss_smart2010") #rename some of the variables

brfss = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  mutate(topic = as.factor(topic)) %>%
  filter(topic == "Overall Health") %>%
  mutate(response = as.factor(response)) %>% 
  mutate(response = factor(response, levels = c("Poor", "Fair", "Good", "Very Good", "Excellent")))
```

Let's determine how many states were observed at 7 or more locations in 2002 and 2010. 

```{r}
brfss %>% 
  filter(year %in% c(2002, 2010)) %>% 
  select(locationabbr, geo_location, year) %>% 
  distinct() %>% 
  group_by(locationabbr, year) %>% 
  summarize(n_obs = n()) %>%
  filter(n_obs >= 7) %>% 
  arrange(year)
```
In 2002, CT, FL, MA, NC, NJ and PA were observed at 7 or more locations. 

In 2010, CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, WA were observed at 7 or more locations. 

Next, we will construct a dataset limited to 'Excellent' responses and containing year, state and a variable averaging data_value across locations within a state. 

```{r}
brfss %>%
  filter(response == "Excellent") %>% 
  group_by(locationabbr, geo_location) %>% 
  mutate(mean_data_value = mean(data_value)) %>% 
  select(year, locationabbr, mean_data_value) %>% 
  ggplot(aes(x = year, y = mean_data_value, color = locationabbr)) + 
  geom_line(aes(group = locationabbr)) +
  theme(legend.position = "right")
  
```

The majority of mean data values are under 30. 

Next, we'll make a two-panel plot showing the distribution of data_value for responses ("Poor" to "Excellent") for 2006 and 2010 among locations in NY State.

```{r}
brfss %>% 
  filter(response %in% c("Poor", "Fair", "Good",
                         "Very Good", "Excellent"),
         year %in% c(2006,2010)) %>% 
  group_by(locationabbr, geo_location) %>% 
  ggplot(aes(x = response, y = data_value)) + 
  geom_point() + 
  facet_grid(. ~ year)
```

